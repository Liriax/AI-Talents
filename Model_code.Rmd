---
title: "Tech Skillytics"
author: "T(AI)lents"
date: "20/12/2020"
output:
  pdf_document:
    dev: png
  keep_tex: yes
  word_document: default
header-includes:
- \usepackage{dcolumn}
- \usepackage{booktabs}
- \usepackage{sectsty} \sectionfont{\centering}
- \usepackage{indentfirst}
- \usepackage{setspace}\onehalfspacing
fontsize: 11pt


---


```{r setup, include=FALSE, message=FALSE}

knitr::opts_chunk$set(echo = T, cache = TRUE)
options(scipen = 99999) # Do not wish to have scientific  notations.


```


```{r, warning = F, message = F}
# loading the required packages:

library(FactoMineR)
library(tibble)
library(tm)
library(tidyverse)
library(parallel)
library(ggplot2)
library(tidytext)
require(sentimentr)
library(SentimentAnalysis)
library(lexicon)
require(tokenizers)
require(stringr)

```



\pagebreak

\tableofcontents

\pagebreak




### 1. Cleaning up the edx data: 

```{r}

# Cleaning the edx data----

DF_edx <- read.csv("edx_courses.csv") %>% 
  select(title, course_description , course_length , course_effort) %>% 
  rename( length_in_weeks = course_length )

DF_edx$course_description <- DF_edx$course_description %>% 
  tolower() %>%
  gsub("[^[:alnum:]|\\+]", " ", .) %>% 
  gsub('\\b\\w{21,}\\s','', .) %>% 
  removeWords(., stopwords(kind = "en")) %>% 
  gsub("[[:space:]]+", " ", .)

DF_edx$title <- DF_edx$title %>% 
  tolower() %>%
  gsub("[^[:alnum:]|\\+]", " ", .) %>% 
  gsub('\\b\\w{21,}\\s','', .) %>% 
  removeWords(., stopwords(kind = "en")) %>% 
  gsub("[[:space:]]+", " ", .)

DF_edx$length_in_weeks <- DF_edx$length_in_weeks  %>% 
  gsub(" Weeks", "", .) %>% 
  as.numeric()

DF_edx <- DF_edx %>% 
  mutate(min_hours_per_week = as.numeric(gsub("â€“.+", "", course_effort)),
         max_hours_per_week = as.numeric(gsub(".+â€“| hours per week", "", course_effort)), 
         avg_hours = (min_hours_per_week +max_hours_per_week)/2,
         expected_hours = avg_hours*length_in_weeks) %>%
  select(title, course_description , expected_hours)



```


----

### 2. Checking the skills present in the edx data



```{r}

# loading all skills and crafting our own dictionary of skills

DF_jobs <- read.csv("Model/test.csv")

#making a vector with all the skill names

All_skills <- paste(c(DF_jobs$required_skills), collapse = ", ") %>% 
  scan(text = .,
       what = "character",
       quote = "", 
       sep = ",") %>% 
  trimws(., which = "both") 



Freq_skills <- table(All_skills)%>% 
  sort(decreasing = T) %>% 
  as.data.frame() %>% 
  filter(Freq > 4)

Skill_dictionary <- as.vector(as.character(Freq_skills$All_skills)) %>% 
  gsub("\\+", "\\\\+", .)



```


```{r}



#checking which skills are present in the dataset.

skill_check <- cbind(DF_edx, sapply(Skill_dictionary, function(w){grepl(paste0("\\b",w,"\\b"),DF_edx$course_description)}))

# filtering out the skills on the edx DF

DF_edx$Skills <-apply(
  skill_check[,5:1194], 1, 
  function(u) paste( names(which(u)), collapse=", " ) 
)

#getting the average time it takes to learn a skill 


Skill_times <- tibble( Skill = colnames(skill_check[,5:1194]), Skill_time = colMeans( skill_check[,5:1194]*skill_check$expected_hours )) 



write.csv(DF_edx,"Cleaned_edx.csv", row.names = F)

write.csv(Skill_times,"Skill_times.csv", row.names = F)



```








































